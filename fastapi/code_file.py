# -*- coding: utf-8 -*-
"""code_file.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TJ0baCrgKsVeWbkMOVIISg8urU9o8TLS

### 1. Importing Necesseties
"""

# Commented out IPython magic to ensure Python compatibility.
import re
import string
import numpy as np
import random
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
from plotly import graph_objs as go
import plotly.express as px
import plotly.figure_factory as ff
from collections import Counter

from sklearn.preprocessing import LabelEncoder

from PIL import Image
from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator


import nltk
from nltk.corpus import stopwords

from tqdm import tqdm
import os
import nltk
import spacy
import random
from spacy.util import compounding
from spacy.util import minibatch

import warnings
warnings.filterwarnings("ignore")

#pip install transformers[torch] accelerate>=0.20.1

#pip install openai==0.28.1



"""### 2. Importing dataset into dataframe"""

train = pd.read_excel('data.xlsx', sheet_name='Train')
test = pd.read_excel('data.xlsx', sheet_name='Test')

train.head()

"""### EDA"""

print(train.shape)
print(test.shape)

"""##### So We have 8589 tweets in the train set and 504 tweets in the test set"""

train.info()

train.isnull().sum()

train.dropna(subset=['tweet_text'], inplace=True)

test.info()

test.isnull().sum()

train.head()

# Rename columns
new_column_names = {'emotion_in_tweet_is_directed_at': 'emotion', 'is_there_an_emotion_directed_at_a_brand_or_product': 'sentiment'}
train = train.rename(columns=new_column_names)

# Convert 'No emotion toward brand or product' and "I can't tell" to 'Neutral emotion'
neutral_sentiments = ['No emotion toward brand or product', "I can't tell"]
train['sentiment'] = train['sentiment'].apply(lambda x: 'Neutral emotion' if x in neutral_sentiments else x)

train.describe()

temp = train.groupby('sentiment').count()['tweet_text'].reset_index().sort_values(by='tweet_text',ascending=False)
temp.style.background_gradient(cmap='Purples')

plt.figure(figsize=(8,4))
sns.countplot(x='sentiment',data=train)
plt.show()

fig = go.Figure(go.Funnelarea(
    text =temp.sentiment,
    values = temp.tweet_text,
    title = {"position": "top center", "text": "Funnel-Chart of Sentiment Distribution"}
    ))
fig.show()

"""### Cleaning the Corpus"""

def clean_text(text):
    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation
    and remove words containing numbers.'''
    text = str(text).lower()
    text = re.sub('\[.*?\]', '', text)
    text = re.sub('https?://\S+|www\.\S+', '', text)
    text = re.sub('<.*?>+', '', text)
    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)
    text = re.sub('\n', '', text)
    text = re.sub('\w*\d\w*', '', text)
    return text

train['tweet_text'] = train['tweet_text'].apply(lambda x:clean_text(x))

train.head()

"""### Remove unnecessary stop words"""

import nltk
nltk.download('stopwords')
STOPWORDS = set(stopwords.words('english'))

train['tweet_text'] = train['tweet_text'].apply(lambda text: ' '.join([word for word in text.split() if word.lower() not in STOPWORDS]))

train.shape

train.head()

#remove symbols containing text with unwanted symbols
  train['tweet_text'] = train['tweet_text'].str.replace('[^a-zA-Z0-9\s]', '', regex=True)

"""### lets see which are the most important words on the train data."""

# Generate the word cloud
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(str(train['tweet_text']))

# Display the word cloud using matplotlib
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.show()

train_data=train.head(100)

"""# fine-tune-bert"""

# Initialize LabelEncoder
label_encoder = LabelEncoder()

# Fit and transform the 'Category' column
train['sentiment'] = label_encoder.fit_transform(train['sentiment'])

# Display the mapping between original text and encoded number
class_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))
print("Class Mapping:")
print(class_mapping)

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score
import torch
from transformers import TrainingArguments, Trainer
from transformers import BertTokenizer, BertForSequenceClassification

from transformers import BertTokenizer, BertForSequenceClassification
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
model = BertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=3)

X = list(train["tweet_text"])
y = list(train['sentiment'])
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2,stratify=y)
X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)
X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)

X_train_tokenized.keys()

# Create torch dataset
class Dataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels:
            item["labels"] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings["input_ids"])

train_dataset = Dataset(X_train_tokenized, y_train)
val_dataset = Dataset(X_val_tokenized, y_val)

def compute_metrics(p):
    print(type(p))
    pred, labels = p
    pred = np.argmax(pred, axis=1)

    accuracy = accuracy_score(y_true=labels, y_pred=pred)
    recall = recall_score(y_true=labels, y_pred=pred, average='weighted')
    precision = precision_score(y_true=labels, y_pred=pred, average='weighted')
    f1 = f1_score(y_true=labels, y_pred=pred, average='weighted')

    return {"accuracy": accuracy, "precision": precision, "recall": recall, "f1": f1}

# Define Trainer
args = TrainingArguments(
    output_dir="output",
    num_train_epochs=5,
    per_device_train_batch_size=32

)
trainer = Trainer(
    model=model,
    args=args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    compute_metrics=compute_metrics
)

trainer.train()

trainer.evaluate()

np.set_printoptions(suppress=True)

trainer.save_model('CustomModel')

model_2 = BertForSequenceClassification.from_pretrained("CustomModel")

text ="iphone hrs tweeting riseaustin dead need upgrade plugin stations sxsw"
inputs = tokenizer(text,padding = True, truncation = True, return_tensors='pt')
outputs = model_2(**inputs)
predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
predictions = predictions.cpu().detach().numpy()
predictions

class_names = ['Negative emotion', 'Neutral emotion', 'Positive emotion']

# Assuming predictions is a numpy array containing the model's output probabilities
predicted_class_indices = np.argmax(predictions, axis=1)

# Map indices to class names
predicted_class_names = [class_names[idx] for idx in predicted_class_indices]

print(predicted_class_names)

"""##USING LLM"""

train_data.head()

train_data['tweet_text'] = train_data['tweet_text'].str.strip()
train_data['sentiment'] = train_data['sentiment'].str.strip()

"""###Fine tune LLM model"""

train_data['tweet_text'] = train_data['tweet_text'] + "\n\nIntent:\n\n"
train_data['sentiment'] = " "+ train_data['sentiment'] + " END"
train_data.head()

train_data=train_data.drop('emotion',axis=1)
train_data.columns = ['prompt','completion']
train_data.head(2)

train_data.to_json("train_sample.jsonl", orient='records', lines=True)

!openai tools fine_tunes.prepare_data -f train_sample.jsonl

import os
os.environ['OPENAI_API_KEY'] = "key"

!openai api fine_tunes.create -t "train_sample_prepared_train.jsonl" -v "train_sample_prepared_valid.jsonl" -m 'davinci'

!openai api fine_tunes.follow -i ft-fr3alqZHDFi0lUTmK1FkQ2xw

prompt = "iphone is not working properly\n\nIntent:\n\n"

import openai
openai.api_key ='key'
response = openai.Completion.create(
  model="davinci:ft-voiceback-analytics-pvt-ltd-2023-12-29-06-52-13",
  prompt=prompt,
  max_tokens=5,
  temperature=0,
  top_p=1,
  frequency_penalty=0,
  presence_penalty=0,
  stop=[" END"]
)
print(response['choices'][0]['text'])

